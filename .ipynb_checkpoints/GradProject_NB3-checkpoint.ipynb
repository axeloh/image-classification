{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRn67sI_bzrm"
   },
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsKiQRYtbzro"
   },
   "source": [
    "<h2>  Part Three: Classifier training and performance assessment. </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gc2wn_6IBun6"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "<<<<<<< local\n",
    "from sklearn.decomposition import PCA\n",
    "=======\n",
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(42)\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46179,
     "status": "ok",
     "timestamp": 1574673545548,
     "user": {
      "displayName": "Henrik Høiness",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU_UzKC8CKFaMzdXHG3v2miAUiqbdhU_utY4l9=s64",
      "userId": "05134007726078583058"
     },
     "user_tz": 480
    },
    "id": "OPpevWkU2raj",
    "outputId": "df9ccfce-d6dc-409c-c20e-eea39c7c8305"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2HbJKLRbzrr"
   },
   "source": [
    "#### Retrieving and preprocessing of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1574678666514,
     "user": {
      "displayName": "Henrik Høiness",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU_UzKC8CKFaMzdXHG3v2miAUiqbdhU_utY4l9=s64",
      "userId": "05134007726078583058"
     },
     "user_tz": 480
    },
    "id": "4fkkK5APDZRb",
    "outputId": "87d21858-b8c7-461c-8982-b0b2564fb7a5"
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.GradProject_NB2 import preprocess_part_one, preprocess_part_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 421,
     "status": "error",
     "timestamp": 1574675788370,
     "user": {
      "displayName": "Henrik Høiness",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU_UzKC8CKFaMzdXHG3v2miAUiqbdhU_utY4l9=s64",
      "userId": "05134007726078583058"
     },
     "user_tz": 480
    },
    "id": "B7Qeocn8Beni",
    "outputId": "c1019e4b-4e96-4ee7-e30b-18bb86dd68a5"
   },
   "outputs": [],
   "source": [
    "training_data = preprocess_part_one(None, True, True)\n",
    "print('-'*50)\n",
    "train_part, val_part = train_test_split(training_data, test_size=0.1)\n",
    "k = 10\n",
    "train, val = preprocess_part_two(train_part, val_part, k)\n",
    "\n",
    "train_x, train_y = train.drop(columns=['Label']), train['Label']\n",
    "val_x, val_y = val.drop(columns=['Label']), val['Label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_x_scaled = scaler.fit_transform(train_x)\n",
    "val_x_scaled = scaler.transform(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "def rmse(actual_y, predicted_y):\n",
    "    \"\"\"\n",
    "    The root mean square error between the prediction and the ground truth\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((actual_y - predicted_y)**2)/len(predicted_y))\n",
    "\n",
    "def compute_CV_rmse_and_acc(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 5 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the MSE on that subset (the validation set)\n",
    "    You should be fitting 5 models total.\n",
    "    Return the average MSE of these 5 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation error and accuracy for the 5 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=5)\n",
    "    validation_errors = []\n",
    "    validation_accuracies = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        \n",
    "        # Split the data\n",
    "        split_X_train, split_X_valid = np.take(X_train, train_idx, axis=0), np.take(X_train, valid_idx, axis=0)\n",
    "        split_Y_train, split_Y_valid = np.take(Y_train, train_idx, axis=0), np.take(Y_train, valid_idx, axis=0)\n",
    "        \n",
    "        # Fit the model on the training split\n",
    "        model.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        preds = model.predict(split_X_valid)\n",
    "        error = rmse(split_Y_valid, preds)\n",
    "        acc = accuracy_score(split_Y_valid, preds)\n",
    "        \n",
    "        validation_errors.append(error)\n",
    "        validation_accuracies.append(acc)\n",
    "        \n",
    "    return np.mean(validation_errors), np.mean(validation_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Beginning preprocessing part two\n",
      "[INFO] Reading images\n",
      "\t- Fetching label 'airplanes'\n",
      "\t- Fetching label 'bear'\n",
      "\t- Fetching label 'blimp'\n",
      "\t\t- Gray image ('blimp_0022.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'comet'\n",
      "\t\t- Gray image ('comet_0006.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0011.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0013.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0021.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0036.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0038.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0041.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0049.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0052.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0053.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0057.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0058.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'crab'\n",
      "\t\t- Gray image ('crab_0045.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'dog'\n",
      "\t- Fetching label 'dolphin'\n",
      "\t\t- Gray image ('dolphin_0025.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'giraffe'\n",
      "\t- Fetching label 'goat'\n",
      "\t- Fetching label 'gorilla'\n",
      "\t\t- Gray image ('gorilla_0128.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'kangaroo'\n",
      "\t- Fetching label 'killer-whale'\n",
      "\t- Fetching label 'leopards'\n",
      "\t- Fetching label 'llama'\n",
      "\t- Fetching label 'penguin'\n",
      "\t- Fetching label 'porcupine'\n",
      "\t- Fetching label 'teddy-bear'\n",
      "\t- Fetching label 'triceratops'\n",
      "\t- Fetching label 'unicorn'\n",
      "\t- Fetching label 'zebra'\n",
      "[INFO] Downsampling images..\n",
      "[INFO] Trimming images\n",
      "[INFO] Scaling images\n",
      "[INFO] Adding features: size, aspect_ratio, red-, green-, blue- and gray-intensity\n",
      "[INFO] Adding histogram features\n",
      "[INFO] Adding stride features\n",
      "[INFO] Done preprocessing part one.\n",
      "--------------------------------------------------\n",
      "[INFO] Beginning preprocessing part two\n",
      "[INFO] Getting descriptors\n",
      "[INFO] Building descriptor dictionary\n",
      "[INFO] Fitting KMeans with k=10 to training descriptors\n",
      "[INFO] Adding cluster features\n",
      "[INFO] Done preprocessing part two.\n",
      "**** k=10, down_sample=True, decriptor_limit=6000****\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation mean error: 7.362363201715982\n",
      "Cross validation mean accuracy: 0.2386899563318777\n",
      "Test accuracy: 0.3359375\n",
      "\n",
      "----------\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "Cross validation mean error: 7.454677074256351\n",
      "Cross validation mean accuracy: 0.20822479589899373\n",
      "Test accuracy: 0.265625\n",
      "\n",
      "----------\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "Cross validation mean error: 7.020530848191015\n",
      "Cross validation mean accuracy: 0.2961534080121512\n",
      "Test accuracy: 0.25\n",
      "\n",
      "----------\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "Cross validation mean error: 6.440301243803679\n",
      "Cross validation mean accuracy: 0.40503512435921774\n",
      "Test accuracy: 0.3984375\n",
      "\n",
      "----------\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "Cross validation mean error: 10.349657969188433\n",
      "Cross validation mean accuracy: 0.05139927852667553\n",
      "Test accuracy: 0.296875\n",
      "\n",
      "----------\n",
      "[INFO] Beginning preprocessing part two\n",
      "[INFO] Reading images\n",
      "\t- Fetching label 'airplanes'\n",
      "\t- Fetching label 'bear'\n",
      "\t- Fetching label 'blimp'\n",
      "\t\t- Gray image ('blimp_0022.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'comet'\n",
      "\t\t- Gray image ('comet_0006.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0011.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0013.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0021.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0036.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0038.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0041.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0049.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0052.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0053.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0057.jpg') was loaded, converting to RGB\n",
      "\t\t- Gray image ('comet_0058.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'crab'\n",
      "\t\t- Gray image ('crab_0045.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'dog'\n",
      "\t- Fetching label 'dolphin'\n",
      "\t\t- Gray image ('dolphin_0025.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'giraffe'\n",
      "\t- Fetching label 'goat'\n",
      "\t- Fetching label 'gorilla'\n",
      "\t\t- Gray image ('gorilla_0128.jpg') was loaded, converting to RGB\n",
      "\t- Fetching label 'kangaroo'\n",
      "\t- Fetching label 'killer-whale'\n",
      "\t- Fetching label 'leopards'\n",
      "\t- Fetching label 'llama'\n",
      "\t- Fetching label 'penguin'\n",
      "\t- Fetching label 'porcupine'\n",
      "\t- Fetching label 'teddy-bear'\n",
      "\t- Fetching label 'triceratops'\n",
      "\t- Fetching label 'unicorn'\n",
      "\t- Fetching label 'zebra'\n",
      "[INFO] Downsampling images..\n",
      "[INFO] Trimming images\n",
      "[INFO] Scaling images\n",
      "[INFO] Adding features: size, aspect_ratio, red-, green-, blue- and gray-intensity\n",
      "[INFO] Adding histogram features\n",
      "[INFO] Adding stride features\n",
      "[INFO] Done preprocessing part one.\n",
      "--------------------------------------------------\n",
      "[INFO] Beginning preprocessing part two\n",
      "[INFO] Getting descriptors\n",
      "[INFO] Building descriptor dictionary\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-453eb0af9518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtrain_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_part_two\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptor_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Koding/machine_learning/DS200_final_project/final_project/GradProject_NB2.ipynb\u001b[0m in \u001b[0;36mpreprocess_part_two\u001b[0;34m(training_set, test_set, k, descriptor_limit)\u001b[0m\n\u001b[1;32m    953\u001b[0m      \u001b[0;34m\"timestamp\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1574671960368\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m      \"user\": {\n\u001b[0;32m--> 955\u001b[0;31m       \u001b[0;34m\"displayName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Henrik Høiness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m       \u001b[0;34m\"photoUrl\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"https://lh3.googleusercontent.com/a-/AAuE7mAU_UzKC8CKFaMzdXHG3v2miAUiqbdhU_utY4l9=s64\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       \u001b[0;34m\"userId\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"05134007726078583058\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Koding/machine_learning/DS200_final_project/final_project/GradProject_NB2.ipynb\u001b[0m in \u001b[0;36mbuild_descriptor_dict\u001b[0;34m(descriptor_df)\u001b[0m\n\u001b[1;32m    663\u001b[0m     }\n\u001b[1;32m    664\u001b[0m    ],\n\u001b[0;32m--> 665\u001b[0;31m    \"source\": [\n\u001b[0m\u001b[1;32m    666\u001b[0m     \u001b[0;34m\"training_data[training_data[\\\"Label\\\"]==12][\\\"size\\\"].describe()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m    ]\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \"\"\"\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# ndarray compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \"\"\"\n\u001b[1;32m    725\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "for k in [10, 100, 200, 500]:\n",
    "    for down_sample in [True, False]:\n",
    "        for descriptor_limit in [6000, 10000, 30000]:\n",
    "            #blockPrint()\n",
    "            training_data = preprocess_part_one(None, True, down_sample)\n",
    "            print('-'*50)\n",
    "            train_part, val_part = train_test_split(training_data, test_size=0.1)\n",
    "            train, val = preprocess_part_two(train_part, val_part, k, descriptor_limit)\n",
    "\n",
    "            train_x, train_y = train.drop(columns=['Label']), train['Label']\n",
    "            val_x, val_y = val.drop(columns=['Label']), val['Label']\n",
    "            \n",
    "            scaler = MinMaxScaler()\n",
    "            train_x_scaled = scaler.fit_transform(train_x)\n",
    "            val_x_scaled = scaler.transform(val_x)\n",
    "            \n",
    "            #enablePrint()\n",
    "            print(f'**** k={k}, down_sample={down_sample}, decriptor_limit={descriptor_limit}****')\n",
    "            \n",
    "            model = LogisticRegression(max_iter=500)\n",
    "            model.fit(train_x_scaled, train_y)\n",
    "            preds = model.predict(val_x_scaled)\n",
    "            print(type(model))\n",
    "            error, acc = compute_CV_rmse_and_acc(model, train_x, train_y)\n",
    "            print(f\"Cross validation mean error: {error}\")\n",
    "            print(f\"Cross validation mean accuracy: {acc}\")\n",
    "            print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")\n",
    "            print('-'*10)\n",
    "            \n",
    "            \n",
    "            model = KNeighborsClassifier(10, weights='distance')\n",
    "            model.fit(train_x_scaled, train_y)\n",
    "            preds = model.predict(val_x_scaled)\n",
    "            print(type(model))\n",
    "            error, acc = compute_CV_rmse_and_acc(model, train_x, train_y)\n",
    "            print(f\"Cross validation mean error: {error}\")\n",
    "            print(f\"Cross validation mean accuracy: {acc}\")\n",
    "            print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")\n",
    "            print('-'*10)\n",
    "            \n",
    "            model = DecisionTreeClassifier()\n",
    "            model.fit(train_x_scaled, train_y)\n",
    "            preds = model.predict(val_x_scaled)\n",
    "            print(type(model))\n",
    "            error, acc = compute_CV_rmse_and_acc(model, train_x, train_y)\n",
    "            print(f\"Cross validation mean error: {error}\")\n",
    "            print(f\"Cross validation mean accuracy: {acc}\")\n",
    "            print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")\n",
    "            print('-'*10)\n",
    "            \n",
    "            model = RandomForestClassifier(n_estimators=800)\n",
    "            model.fit(train_x_scaled, train_y)\n",
    "            preds = model.predict(val_x_scaled)\n",
    "            print(type(model))\n",
    "            error, acc = compute_CV_rmse_and_acc(model, train_x, train_y)\n",
    "            print(f\"Cross validation mean error: {error}\")\n",
    "            print(f\"Cross validation mean accuracy: {acc}\")\n",
    "            print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")\n",
    "            print('-'*10)\n",
    "            \n",
    "            model = SVC(kernel='rbf',C=10, gamma=0.01)\n",
    "            model.fit(train_x_scaled, train_y)\n",
    "            preds = model.predict(val_x_scaled)\n",
    "            print(type(model))\n",
    "            error, acc = compute_CV_rmse_and_acc(model, train_x, train_y)\n",
    "            print(f\"Cross validation mean error: {error}\")\n",
    "            print(f\"Cross validation mean accuracy: {acc}\")\n",
    "            print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")\n",
    "            print('-'*10)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPgsvYbhbzrs"
   },
   "source": [
    "### Logistic Regression\n",
    "##### Performing  5-fold cross validation for deciding hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPgsvYbhbzrs"
   },
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "### Logistic Regression\n",
    "##### Fitting model to training set with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1074,
     "status": "error",
     "timestamp": 1574642755220,
     "user": {
      "displayName": "Axel Oevreboe Harstad",
      "photoUrl": "",
      "userId": "00313732855330319553"
     },
     "user_tz": 480
    },
    "id": "p_F4f5Slbzrt",
    "outputId": "4d14a70d-77fb-43e6-98f0-24c5cb84814c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.661046578704598\n",
      "Accuracy: 0.3475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "model = LogisticRegression(multi_class='multinomial', solver= 'lbfgs', penalty='l2', max_iter=1000)\n",
    "\n",
    "error, acc = compute_CV_rmse_and_acc(model, x_train_scaled, y_train)\n",
    "print(f\"Mean RMSE: {error}\")\n",
    "print(f\"Accuracy: {acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.2955977869473685\n",
      "Test accuracy: 0.3388704318936877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver= 'newton-cg')\n",
    "\n",
    "model.fit(train_x_scaled, train_y)\n",
    "preds = model.predict(val_x_scaled)\n",
    "print(f\"Mean RMSE: {rmse(val_y, preds)}\")\n",
    "print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "print(collections.Counter(preds))\n",
    "print(collections.Counter(val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcCxllL3bzrv"
   },
   "source": [
    "### K-nearest Neighbors\n",
    "##### Predicting training set with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OLQdVbRAbzrw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.859133726178034\n",
      "Accuracy: 0.2891666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "model = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "\n",
    "error, acc = compute_CV_rmse_and_acc(model, x_train_scaled, y_train)\n",
    "print(f\"Mean RMSE: {error}\")\n",
    "print(f\"Accuracy: {acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(10, weights='distance')\n",
    "model.fit(train_x_scaled, train_y)\n",
    "preds = model.predict(val_x_scaled)\n",
    "acc = accuracy_score(preds, val_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyf9J_TLbzry"
   },
   "source": [
    "### Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.592807920686736\n",
      "Test accuracy: 0.27906976744186046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "model = KNeighborsClassifier(10, weights='distance')\n",
    "\n",
    "model.fit(x_train_scaled, y_train)\n",
    "preds = model.predict(x_test_scaled)\n",
    "print(f\"Mean RMSE: {rmse(y_test, preds)}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, preds)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPQlFzuebzry"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 2.5471683325482872\n",
      "Accuracy: 0.715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "error, acc = compute_CV_rmse_and_acc(model, x_train_scaled, y_train)\n",
    "print(f\"Mean RMSE: {error}\")\n",
    "print(f\"Accuracy: {acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_x_scaled, train_y)\n",
    "preds = model.predict(val_x_scaled)\n",
    "acc = accuracy_score(preds, val_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.209787580426559\n",
      "Accuracy: 0.29900332225913623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(x_train_scaled, y_train)\n",
    "preds = model.predict(x_test_scaled)\n",
    "print(f\"Mean RMSE: {rmse(y_test, preds)}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, preds)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_T-JIq8bzr1"
   },
   "source": [
    "### Random Forest\n",
    "##### Predicting training set with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZ8TnM93bzr1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.934267455506964\n",
      "Accuracy: 0.07416666666666667\n",
      "\n",
      "\n",
      "Most importance features:\n",
      "Feature name: stride_feat_54, Importance=0.004889143313085988\n",
      "Feature name: stride_feat_73, Importance=0.004629313685160276\n",
      "Feature name: stride_feat_74, Importance=0.004492257667117635\n",
      "Feature name: stride_feat_49, Importance=0.004385448282853304\n",
      "Feature name: stride_feat_28, Importance=0.004384583985446212\n",
      "Feature name: stride_feat_97, Importance=0.00436587231331786\n",
      "Feature name: AspectRatio, Importance=0.0043648847306119185\n",
      "Feature name: stride_feat_72, Importance=0.004358104816712034\n",
      "Feature name: stride_feat_91, Importance=0.004302289851897213\n",
      "Feature name: stride_feat_108, Importance=0.004215192398012875\n",
      "Feature name: stride_feat_56, Importance=0.004200022683300562\n",
      "Feature name: stride_feat_111, Importance=0.004192143923326466\n",
      "Feature name: stride_feat_124, Importance=0.0041783881997675566\n",
      "Feature name: stride_feat_140, Importance=0.0041588178861251416\n",
      "Feature name: stride_feat_50, Importance=0.004148726827092951\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=800, random_state=42)\n",
    "model.fit(train_x_scaled, train_y)\n",
    "preds = model.predict(val_x_scaled)\n",
    "acc = accuracy_score(preds, val_y)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "s = model.feature_importances_\n",
    "index_importance_sorted = sorted(range(len(s)), key=lambda k: s[k], reverse=True)\n",
    "top_index = index_importance_sorted[:50]\n",
    "\n",
    "print(\"\\nMost importance features:\")\n",
    "for index in top_index:\n",
    "    print(f\"Feature name: {train_x.columns[index]}, Importance={s[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing K-fold grid search to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_params())\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    preds = model.predict(test_features)\n",
    "    accuracy = accuracy_score(preds, test_labels)\n",
    "    print('Accuracy = {:0.2f}%.'.format(100*accuracy))\n",
    "    return accuracy\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(train_x, train_y)\n",
    "base_accuracy = evaluate(base_model, val_x, val_y)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, val_x, val_y)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.772771359915209\n",
      "Test accuracy: 0.07641196013289037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=800)\n",
    "\n",
    "model.fit(train_x_scaled, train_y)\n",
    "preds = model.predict(val_x_scaled)\n",
    "print(f\"Mean RMSE: {rmse(val_y, preds)}\")\n",
    "print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTudbrXEbzr4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.522211213377022\n",
      "Accuracy: 0.08416666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "<<<<<<< LOCAL CELL DELETED >>>>>>>\n",
    "model = SVC(kernel='rbf',C=10, gamma=0.01, decision_function_shape='ovo')\n",
    "\n",
    "error, acc = compute_CV_rmse_and_acc(model, x_train_scaled, y_train)\n",
    "print(f\"Mean RMSE: {error}\")\n",
    "print(f\"Accuracy: {acc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE: 6.4853527787200465\n",
      "Test accuracy: 0.0664451827242525\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf',C=10, gamma=0.01)\n",
    "\n",
    "model.fit(train_x_scaled, train_y)\n",
    "preds = model.predict(val_x_scaled)\n",
    "print(f\"Mean RMSE: {rmse(val_y, preds)}\")\n",
    "print(f\"Test accuracy: {accuracy_score(val_y, preds)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**<<<<<<< local**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sources:\n",
    "- https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**=======**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "* https://en.wikipedia.org/wiki/Logistic_regression\n",
    "* https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-rest\n",
    "* https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "* https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "* https://en.wikipedia.org/wiki/Random_forest\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**>>>>>>> remote**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GradProject_NB3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
